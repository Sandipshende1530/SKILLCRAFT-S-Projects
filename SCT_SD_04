/*First, make sure you have the required libraries installed:

pip install requests beautifulsoup4
*/


import requests
from bs4 import BeautifulSoup
import csv

def extract_product_info(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')

    products = []
    for product in soup.select('.product'):  # Adjust the selector based on the website's structure
        name = product.select_one('.product-name').get_text(strip=True)
        price = product.select_one('.product-price').get_text(strip=True)
        rating = product.select_one('.product-rating').get_text(strip=True)
        products.append([name, price, rating])

    return products

def save_to_csv(products, filename):
    with open(filename, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(['Name', 'Price', 'Rating'])
        writer.writerows(products)

if __name__ == "__main__":
    url = 'https://example.com/products'  # Replace with the actual URL
    products = extract_product_info(url)
    save_to_csv(products, 'products.csv')
    print("Product information saved to products.csv")
